{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Homework 1\n",
    "\n",
    "*Part of the course:\n",
    "Introduction to Machine Learning (code: KI2V20001), 26/04/2021 to 02/07/2021, Utrecht University*\n",
    "\n",
    "Total points: 15\n",
    "\n",
    "[Chide (25apr2021): distribute points over assignments.]\n",
    "\n",
    "[Chide (26apr2021)|: chop up this assignment into several files for the different due-dates.]\n",
    "\n",
    "[Chide (26apr2021)|; Specify more precisely what parts the students have to read from the resources I refer to.]\n",
    "\n",
    "Deadline: dayname dd/mm/2021 by 20h (the day before the next lecture)\n",
    "\n",
    "Submit one ipynb file per pair, with filename: ```TODO_IML2021_wg#_lastname1_lastname2.ipynb```, with your group number in place of the # (if you're in different groups, pick one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handy tools for math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can use [$\\LaTeX$](https://jupyterbook.org/content/math.html) to write down mathematical expressions in Jupyter notebooks. A nice (machine learning-based!) tool to quickly find out how to write down specific math symbols is: http://detexify.kirelabs.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability theory and statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability theory and statistics form the backbone of Machine Learning. There are quite some machine learning experts, such as for example [Michael Littman](https://www.littmania.com/), who even equate machine learning with \"computational statistics\" - i.e. carrying out statistics by employing computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    ">Although not relevant to this course: note that Michael Littman was in the first email attachment ever sent... ;-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it is evident that training in academic probability theory and statistics is essential to understand machine learning well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 1**\n",
    "\n",
    "Probability theory and statistics are, in a certain sense, each other's counterparts. Explain this in at at least 50, but not more than 100 words. Make freely use of sources on the Web, but phrase it in your own words. Add the links to the sources you used. The links should not be included in your word-count.\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "source": [
    "Note: This wasn't a very hard assignment, but an interesting observation that I hadn't thought of before. The hard part was fitting it in 100 words, where after writing what I was thinking I had to cut some words and phrases ( I ended up with a little less than 150 before cutting). Took me 10 minutes overall. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Meta-information about previous assignment**\n",
    "\n",
    "*Learning objectives*\n",
    "\n",
    "* Understanding the difference between probability theory and statistics. These terms are often conflated, but understanding the difference makes it much easier to understand both theories.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first week, we will only focus on probability theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly go through the following probability theory review/summary. It is from the well-known course in machine learning at Stanford University. You do not have to understand everything in one go, just acquaint yourself superficially with the terminology and definitions. More detailed resources will be referred to in the rest of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://cs229.stanford.edu/section/cs229-prob.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, consider the following (game) scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Scenario 1**\n",
    "\n",
    "* Akwasi is blindfolded. \n",
    "* There is a roulette-wheel, which has 5 slots. The slots are labelled with the letters 'A', 'B', up to 'E'. Assume that the roulette-wheel is completely fair: all slots have equal probability that the ball ends up in them.\n",
    "* Annukka spins the roulette-wheel. She observes the outcome. Then she writes down a number as indicated in the following conversion list:\n",
    "    * 'A': -2\n",
    "    * 'B': -1\n",
    "    * 'C':  0\n",
    "    * 'D':  1\n",
    "    * 'E':  2\n",
    "* We will call this number the *private number*.\n",
    "* Then, Annukka spins the roulette-wheel a second time, and observes the second outcome. She writes down a second number. It is obtained by taking the private number, and adding to it the number associated with the second outcome, using the same conversion list.\n",
    "* We will call the second number the *public number*.\n",
    "* She communicates the public number with Akwasi. The private number is kept a secret.\n",
    "* With this information Akwasi tries to guess the first outcome.\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read https://en.wikipedia.org/wiki/Experiment_(probability_theory), and continue with:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 2** <br>\n",
    "\n",
    "1. Briefly describe, without formulas, the random experiment associated with scenario 1. Limit your description to the pure outcomes of the roulette-wheel, ignoring the numbers the players are writing down. <br>\n",
    "2. The random experiment just described, can be considered as consisting of two random experiments that have been merged together. Describe these two random experiments. <br>\n",
    "\n",
    "---\n",
    "<br>"
   ]
  },
  {
   "source": [
    "Note: Unsure what the 1.'s mean here, are these two seperate questions or one? I changed it into 1. and 2. with a linebreak. \n",
    "I would suggest adding that they need to describe the sample space and the function P mentioned in the wikipedia page, to guide them in how to describe such a scenario. Because you mention that you don't want formulas, I was unsure for a second if you did want the mathematical description. Especially the 'probability space' page after this made me question what exactly you were asking here. \n",
    "\n",
    "I read everything in 12 minutes and spent 5 minutes on this assignment. \n",
    "This was easy. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random experiment is the corner stone of probability theory. If there is word of any form of probability, then it is important to become be aware of the underlying random experiment to understand what is happening. All notions, such as \"the probability of\", \"the expected value of\" are relative to the underlying random experiment. In machine learning, for example, a typical random experiment is \"acquiring a dataset for training\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random experiment has been formalised in mathematical terms by Kolmogorov. It is the most widely adopted formal foundation of probability theory (although there are others). Read https://en.wikipedia.org/wiki/Probability_space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 3**\n",
    "\n",
    "Consider the random experiment of spinning the roulette-wheel of scenario 1 once.<br>\n",
    "1. Define the associated outcome space $\\Omega$.<br>\n",
    "2. Define the smallest possible event space $\\mathcal{F_\\textrm{min}}$.<br>\n",
    "3. How many events does the  biggest possible event space $\\mathcal{F_\\textrm{max}}$ contain?<br>\n",
    "4. Suppose, the roulette-wheel would have contained 10 slots. How many events does the biggest possible event space contain?<br>\n",
    "5. (Returning to the 5 slotted roulette-wheel.) Define an event space $\\mathcal{F_{4}}$ that contains exactly 4 events.<br>\n",
    "6. How many event spaces with exactly 4 events are there?<br>\n",
    "7. Now, define a valid probability measure $P$ for the probability space $(\\Omega, \\mathcal{F_{4}}, P)$, using the $\\mathcal{F_{4}}$ you just defined.<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "source": [
    "Note: for clarity I added breaks after each question and changed the numbering to 1-7 rather than 7 times 1.. \n",
    "\n",
    "Here I got confused, as I thought you were already asking for the outcome space in the previous question, so wasn't sure what additional information you wanted here. Maybe I answered too 'mathematically' in the previous one. \n",
    "\n",
    "I  am not sure what other background the students have, but based on only the wikipedia page it is quite difficult to define the probability measure P, as there is no example of it available. The smalles possible event space is also challenging, though the answer is in the stanford document. \n",
    "\n",
    "Overall this took me 15 minutes, with the most time for question 2 (wasn't sure if it could be an empty set) and question 7 (there was no example of a defined probability measure, only mathematical definitions)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the subsection titled \"Properties\" in Section 1 of http://cs229.stanford.edu/section/cs229-prob.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 4**\n",
    "\n",
    "Assume the probability space $(\\Omega, \\mathcal{F_\\textrm{max}}, P)$ as defined in the previous assignment.\n",
    "\n",
    "1. Give an example of two events $A$ and $B$ (in $\\mathcal{F_\\textrm{max}}$) for which holds that probability of both events happening reaches their union bound, i.e. for which holds: $P(A \\cup B) = P(A) + P(B)$.\n",
    "1. Give an example of two events for which holds that the probability of both events happning does **not** reach their union bound. I.e., for which holds: $P(A \\cup B) < P(A) + P(B)$.\n",
    "1. When, in general, does the latter hold for $A$ and $B$?\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "source": [
    "Note: This was very easy as the third question is literally answered in the standford educ document, above the properties subsection. Only took 2/3 minutes. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Meta-information about previous assignment**\n",
    "\n",
    "*Learning objectives*\n",
    "\n",
    "* Getting some intuition for the union bound.\n",
    "\n",
    "*Dependencies*\n",
    "\n",
    "* The union bound is used in the first bound for the probability that $E_\\textrm{in}$ deviates from $E_\\textrm{out}$ in the case of an $\\mathcal{H}$ with multiple hypotheses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables can be considered as a layer on top of the probability space that adds more mathematical \"instruments\" to it to apply probability theory. For important subcategories of random experiments, we are interested in numerically expressible properties, such as averages, etc. Random variables and associated notions are intended to capture these notions. Read https://en.wikipedia.org/wiki/Random_variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 5**\n",
    "\n",
    "1. Let $X_\\textrm{priv}$ be the random variable that is equal to the private number Annukka writes down. Define that random variable. I.e., write down how it maps $\\Omega$ to $\\mathbb{R}$ for every sample in $\\Omega$.\n",
    "1. Suppose Annukka would have written down the letter instead of a numeric value. Is it possible to define a random variable that maps $\\Omega$ to these letters?\n",
    "1. What subset of $\\Omega$ is denoted with the expression \"$X_\\textrm{priv} \\textrm{ is an odd number}$\"?\n",
    "1. Express this subset also in [set builder notation](https://en.wikipedia.org/wiki/Set-builder_notation), in which $X_\\textrm{priv}$ and $\\Omega$ occur as symbols. Hint: an example can be found in the [CS299 probability review](http://cs229.stanford.edu/section/cs229-prob.pdf) and in the article [Event, Wikipedia, 5 April 2021](https://en.wikipedia.org/w/index.php?title=Event_(probability_theory)&oldid=1017892490)\n"
   ]
  },
  {
   "source": [
    "Note: question 5.2 doesn't have a definite answer, because according to the wikipedia page, one can consider random elements as well. For 5.4 you could also specify if you want it by predicate or enumeration (predicate is a lot harder than enumeration, but considering you wanted the symbols included I figured you wanted predicate).\n",
    "This was the hardest exercise so far, due to the unclear nature of 5.2 and the (seemingly double) question of 3 & 4. It took me 10 minutes, including reading all the wiki articles. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "**Meta-information about previous assignment**<br>\n",
    "\n",
    "*Learning objectives*<br>\n",
    "1. Understanding basic notions around random variables, including<br>\n",
    "<tab>    1. Random variables map to $\\mathbb{R}$, and not to anything else.<br>\n",
    "    2. Union bound.<br>\n",
    "    \n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, read https://en.wikipedia.org/wiki/Joint_probability_distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 6**\n",
    "\n",
    "Let $X_\\textrm{pub}$ be the random variable that is equal to the public number Annukka writes down.\n",
    "1. Write down the joint probability distribution of $X_\\textrm{priv}$ and $X_\\textrm{pub}$ in a table. (Tip 1: you can use https://www.tablesgenerator.com/markdown_tables# to more easily create a table in Markdown syntax. Tip 2: in the same tool, with the menu-item *File* $\\rightarrow$ *Paste table data* you can transfer an existing markdown table to continue working on it with the tool.)\n",
    "1. Add to the table the marginal distribution of both $X_\\textrm{priv}$ and $X_\\textrm{pub}$.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 7**\n",
    "\n",
    "1. What is the conditional probability of $X_\\textrm{pub} = 2$ given $X_\\textrm{priv} = 1$? So, what is $P(X_\\textrm{pub} = 2$ | $X_\\textrm{priv} = 1)$\n",
    "1. For what values of $x_\\textrm{priv}$ is $P(X_\\textrm{priv} = x_\\textrm{priv}$ | $X_\\textrm{pub} = 3)$ equal to zero?\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read:\n",
    "* https://en.wikipedia.org/wiki/Expected_value \n",
    "* https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 8**\n",
    "\n",
    "Lets investigate the expected value of $X_\\textrm{priv}$, also written as $E[X_\\textrm{priv}]$.\n",
    "\n",
    "1. What is your intuition about the value of $E[X_\\textrm{priv}]$? Why?\n",
    "1. Derive what it is, using the definition of the expected value. Show your derivation. (The definition is $\\operatorname{E}[X] =\\sum_{i=1}^k x_i\\,p_i=x_1p_1 + x_2p_2 + \\cdots + x_kp_k$.)\n",
    "1. What is your intuition about $E[X_\\textrm{pub}]$? Explain.\n",
    "$X_\\textrm{pub}$ can be seen as the sum of two random variables, $X_\\textrm{priv}$ and, lets call it $X_\\textrm{noise}$. The latter is the number Annukka adds to the private number to obtain the public number.\n",
    "1. What is the relation between $X_\\textrm{noise}$ and $X_\\textrm{priv}$? Express it in a term that has been provided in the reading materials referred to above this assignment.\n",
    "1. So, what is the value of $E[X_\\textrm{noise}]$?\n",
    "1. Derive the value of $E[X_\\textrm{pub}]$, and show your derivation. Tip: there is a very short solution, by taking advantage of one of the [\"properties of the expected value\"](https://en.wikipedia.org/wiki/Expected_value#Basic_properties). \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Scenario 2**\n",
    "\n",
    "Scenario 2 is an extended version of scenario 1. In it, Annukka repeats scenario 1 a number of additional rounds with the following change. For each round $n$ after round 1, the private number is determined by adding the first number she obtains in round $n$, to the private number of the *previous* round, so round $n-1$. So, she could, for example, get two lists like this:\n",
    "\n",
    "| round         | 1  | 2 | 3 | 4 | 5 | 6 |   |\n",
    "|---------------|----|---|---|---|---|---|---|\n",
    "| **private number** | -1 | 1 | 2 | 4 | 4 | 3 |   |\n",
    "| **public number** | -2 | 2 | 4 | 2 | 4 | 4 |   |\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 9**\n",
    "\n",
    "Suppose, Akwasi tries to guess the maximal number that occurs in the private number list. His strategy is simply to pick the maximal public number as the solution. In more formal terms: Let  the random variables $X_{\\textrm{priv}_1}, X_{\\textrm{priv}_2}, \\ldots, X_{\\textrm{priv}_N}$ represent the row of private numbers. Let $X_{\\textrm{priv}_+}$ be the maximal private number, and $X_{\\textrm{pub}_+}$ the maximal public number. Akwasi chooses $X_{\\textrm{pub}_+}$ as the solution. In the example mentioned in Scenario 2, $X_{\\textrm{priv}_+} = X_{\\textrm{pub}_+} = 4$\n",
    "\n",
    "1. Annukka only completes one round. (So, $N = 1$.) Is the probability that Akwasi overestimates the private number equal to the probability that he underestimates it? Or is one probability greater than the other, and if so, which one? Explain your answer in \"intuitive\" terms - no proof needed.\n",
    "1. One can rephrase the previous problem in terms of expected values: Let $X_\\textrm{diff} = X_{\\textrm{pub}_+} - X_{\\textrm{priv}_+}$. What holds: $E[X_\\textrm{diff}] < 0$, $E[X_\\textrm{diff}] = 0$ or $E[X_\\textrm{diff}] > 0$?\n",
    "1. Write down all possible values that $X_\\textrm{diff}$ can take.\n",
    "1. Now, calculate the exact value of $E[X_\\textrm{diff}]$. Tip: you can use the joint probability table you created before.\n",
    "1. What is the \"intuitive\" answer for two rounds ($N = 2$). Explain.\n",
    "1. Calculate the exact value for $E[X_{\\textrm{diff}}]$ in the case $N = 2$.\n",
    "1. What if Akwasi tried to do the opposite: guess the *minimal* number in the private number list, by choosing the minimal public number as the solution? Explain.\n",
    "1. What if Akwasi tried to guess the *average* number in the private number list, by determining the average of the public number list? Explain.\n",
    "1. (Going back to Akwasi guessing the maximal number.) What happens with the expected overestimation $E[X_{\\textrm{diff}}]$ if $N$ becomes bigger? (Intuitive answer suffices.)\n",
    "1. Now, take the limit of the number of rounds to infinity. What happens with the expected overestimation? So, what is $\\lim_{N \\to \\infty}E[X_{\\textrm{diff}}]$.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly go through the following linear algebra review/summary. You do not have to understand everything in one go, just acquiant yourself superficially with the terminology and definitions. More detailed resources will be referred to in the rest of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://cs229.stanford.edu/summer2020/cs229-linalg.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Meta-information**\n",
    "\n",
    "*Learning objectives*\n",
    "\n",
    "* matrix multiplication\n",
    "* transpose\n",
    "* vector innerproduct\n",
    "* vector inner product with matrix multiplication.\n",
    "* norms\n",
    "* orthogonal vectors\n",
    "* vector angles\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Tip** You can generate $\\LaTeX$ matrix source code with https://jasonwarta.github.io/latex-matrix/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read: Matrices and Matrix Operations (2021, January 2) from https://math.libretexts.org/@go/page/1387.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 1**\n",
    "\n",
    "Go through the exercises/examples in the page Matrices and Matrix Operations (2021, January 2) from https://math.libretexts.org/@go/page/1387 that are listed below. However, replace the elements in each matrix with randomly chosen other numbers. Do it in such a way that the resulting problem remains in essence the same. For example, do not change numbers such that the result is much easier to achieve, or that there is no result possible. Solve the problems, while showing all steps you took in the calculation. Do this for the following examples:\n",
    "1. 9.5.2B (addition)\n",
    "1. 9.5.3 (scalar multiplication)\n",
    "1. 9.5.5B (multiplication)\n",
    "1. Verify your answers with a matrix calculator such as https://matrixcalc.org/en/, or if you are already up to it, by using Python in this notebook.\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read \"Strang, G.; Herman, E. “Jed.” (2021, January 2). The Dot Product\" from https://math.libretexts.org/@go/page/2588: everything up to, but not including \"direction angles\". You can skip the proofs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**: one of the authors of the above is a researcher from M.I.T. and has an excellent and very clear step-by-step online course in linear algebra:\n",
    "> https://www.youtube.com/playlist?list=PL49CF3715CB9EF31D.\n",
    "> If you want to refresh your knowledge of linear algebra, do not hesitate to follow a  part of these lectues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 2**\n",
    "\n",
    "Go through the exercises stated in the page \"The Dot Product.\" at https://math.libretexts.org/@go/page/2588 that are listed below. However, replace the elements in each vector with randomly chosen other numbers. Do it in such a way that the resulting problem remains in essence the same. For example, do not change numbers such that the result is much easier to achieve, or that there is no result possible. Solve the problems, while showing all steps you took in the calculation. Do this for the following examples and exercises:\n",
    "1. Exercise 12.3.1.\n",
    "1. Exercise 12.3.3.\n",
    "1. Exercise 12.3.4.\n",
    "\n",
    "1. Given vectors $v$ and $w$. If one writes these vectors as 1-column matrices, then the innerproduct between them, can be expressed by means of a matrix multiplication\": $v^T w$. Suppose we would have written $v$ and $w$ as 1-row matrices instead. How would you then express the innerproduct by means of a matrix multiplication?\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 1**\n",
    "\n",
    "\"Consider a bin that contains red and green marbles, possibly infinitely many. The proportion of red and green marbles in the bin is such that if we pick a marble at random, the probability that it will be red is $\\mu$ and the probability that it will be green is $1-\\mu$. We assume that the value of $\\mu$ is unknown to us.\n",
    "\n",
    "We pick a random sample of N independent marbles (with replacement) from this bin, and observe the fraction v of red marbles within the sample.\" (From: Learning From Data (Abu-Mostafa et al, 2012))\n",
    "\n",
    "\n",
    "1. If $\\mu = 0.7$, use the Hoeffding Inequality to bound the probability that a sample of 8 marbles will have $\\nu \\leq 0.1$. (Based on Exercise 1.9 from Learning From Data (Abu-Mostafa et al, 2012).)\n",
    "1. If $\\mu = 0.8$, find the smallest value for $N$ that one can find with the Hoeffding inequality for which holds that $\\nu$ deviates *at most* $0.05$ from $\\mu$ with a probability of at least $0.99$. (Note that the problem has been formulated in a reversed way from the book. In the book the probability represents the *undesired* situation that $\\mu$ and $\\nu$ deviate more than a predefined threshold. Here it is about the *desired* situation that they deviate at most a given threshold.).\n",
    "1. Akwasi calculates the previous question in another way, and finds a value that is smaller than you found. Is it certain that he made a mistake (assuming you made no mistake in applying Hoeffding)? Why? \n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 2**\n",
    "\n",
    "Suppose that you are confronted with a machine learning problem that is completely unknown to you. The data-set is offered by an alien from a completely different universe, and no context whatsoever is known. Assume that the target function is binary, and has an infinite input space, and could truly be any binary target function. (This is a stronger version of Exercise 1.12 from Learning From Data (Abu-Mostafa et al, 2012).)\n",
    "\n",
    "Tip: first thoroughly read Section 1.3.3 in the book. In particular, focus on \"The feasibility of learning is thus split into two questions\" up to the end of the section. This text explain an essential part of the intuition behind (statistical) machine learning.\n",
    "\n",
    "1. Answer Exercise 1.12 from the book. \n",
    "1. Now, return to the alien's dataset. Suppose that you decide to put *any* possible function in your hypothesis set $\\mathcal{H}$ . Also, assume that you have some way to find the hypothesis $h$ with the lowest $E_\\textrm{in}$.\n",
    "    1. What can you say about the value of $E_\\textrm{in}$?\n",
    "    1. What can you say about how close $E_\\textrm{in}$ and $E_\\textrm{out}$ are together? So, what is the value of $P(|E_\\textrm{in} - E_\\textrm{out}| > \\epsilon)$. Consider any possible value for $\\epsilon$.\n",
    "1. Now, suppose that you decide to choose a less expressive hypothesis set. For example, you limit $\\mathcal{H}$ to all functions that a perceptron can learn.\n",
    "    1. What can you say about the value of $E_\\textrm{in}$?\n",
    "    1. What can you say about the \"generalisation of the error\" from in-of-sample to out-of-sample? So, what is the value of $P(|E_\\textrm{in} - E_\\textrm{out}| > \\epsilon)$. Consider any possible value for $\\epsilon$.\n",
    "1. This solution is not provided in the multiple-choice question formed by Exercise 1.12. So, what does Exercise 1.12 tacitly assume?\n",
    "\n",
    "The conclusion in this question is that the probability is zero that you can learn anything in this situation. Hence, in this case, machine learning is not feasible. This also has a consequence that is essential to machine learning: namely that you always must know, or at least be able to plausibly assume **something** about the problem you are applying your machine learning system to. Otherwise, you cannot construct a useful machine learning system.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Assignment 3**\n",
    "\n",
    "\"Consider the perceptron in two dimensions: $h(x) = sign(w^{T}x)$ where $w = [w_0 , w_1 , w_2]^T$ and $x = [1, x_1 , x_2]^T$. Technically, $x$ has\n",
    "three coordinates, but we call this perceptron two-dimensional because the first\n",
    "coordinate is fixed at 1.\" (From: Problem 1.2 of Learning From Data (Abu-Mostafa et al, 2012).)\n",
    "\n",
    "1. The decision boundary is formed by the region in the input space between the regions where the perceptron classifies the input as $+1$ and $-1$. Show that this decision boundary is a line. Tip: what is the value that $h(x)$ has exactly on this decision boundary, when you do not apply the \"sign\" function2? Using that equation, express $x_2$  in terms of the other variables.\n",
    "1. (With pen and paper/a graphical tool.) Draw a graph of the decision boundary for the case $w = [1, 1, 1]^T$\n",
    "\n",
    "For the following questions, assume that there is no bias, so $w_0 = 0$.\n",
    "\n",
    "1. (With pen and paper/a graphical tool.) Draw a graph of the decision boundary for the case $w = [0, 1, 1]^T$.\n",
    "1. Draw the $w$-vector in the same graph, but limit yourself to $w_1$ and $w_2$ only. So, draw the weight-vector $[w_1, w_2]^T$.\n",
    "1. In the same graph, indicate the regions that are $+1$ and $-1$ by drawing + and - symbols at the right sides of the decision boundary.\n",
    "1. Multiply the weight-vector by $-1$.  (So, create $w' = -w = [-w_0 (=0) , -w_1 , -w_2]^T$.) Create a new graph, and repeat the things you did in the previous three questions.\n",
    "1. Multiply the weight-vector by a constant $c > 0$, and do the same. So, create a graph and draw the decision boundary, weight-vector and +1 and -1 regions in it.\n",
    "1. Now, change the signs of the weight-vector elements of $w$ such that they are opposing. So, consider $w' = [0 , -1 , 1]^T$ and $w' = [0 , 1 , -1]^T$. Draw two graphs for each of these cases as well, with the decision boundary, weight-vector and +1 and -1 regions.\n",
    "1. What could be the relation of the direction of the weight-vector and the direction of the decision boundary, you think? And what is the relation between the direction of the weight vector and the regions +1 and -1?\n",
    "1. (Bonus, not required) try to prove the relation discovered in the previous question, also for the cases $w$'s elements can take *any* value. Tip: use the vector inner product rule/orthogonality rule.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}